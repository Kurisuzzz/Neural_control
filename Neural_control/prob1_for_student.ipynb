{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import sys\n",
    "import h5py\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "from tqdm import tnrange, tqdm_notebook\n",
    "\n",
    "# os.chdir('codes')\n",
    "import models\n",
    "import sklearn.metrics as metrics\n",
    "from PIL import Image\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision.transforms as transforms\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KeysView(<HDF5 file \"npc_v4_data.h5\" (mode r+)>)\n",
      "Datasets: [<HDF5 dataset \"readme\": shape (), type \"|O\">]\n"
     ]
    }
   ],
   "source": [
    "with h5py.File(os.path.join('./', 'npc_v4_data.h5')) as hf:\n",
    "    print(hf.keys())\n",
    "    print('Datasets:', [d for d in hf.values() if isinstance(d, h5py.Dataset)])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KeysView(<HDF5 file \"npc_v4_data.h5\" (mode r+)>)\n",
      "(36, 640, 52)\n",
      "img:  (640, 299, 299, 3)\n",
      "(640, 299, 299)\n",
      "(36, 640, 52)\n",
      "640 52 640\n",
      "images_n (640, 299, 299)\n",
      "(640, 299, 299, 3)\n",
      "<class 'numpy.ndarray'>\n",
      "(640, 299, 299, 3)\n",
      "data_x (640, 3, 299, 299)\n"
     ]
    }
   ],
   "source": [
    "# CHOOSE THE AUGMENTS IF NECESSARY\n",
    "device = 'cuda:0' # device where you put your data and models\n",
    "data_path = './' # the path of the 'npc_v4_data.h5' file\n",
    "batch_size = 50 # the batch size of the data loader\n",
    "insp_layer = 'conv3' # the middle layer extracted from alexnet, available in {'conv1', 'conv2', 'conv3', 'conv4', 'conv5'}\n",
    "\n",
    "\"\"\"\n",
    "The file npc_v4_data.h5 is structured in the following way:\n",
    "images: a tensor of shape [num_images, width, height, num_colors]\n",
    "neural data: a tensor of shape [num_repetitions, num_images, num_neurons]\n",
    "target indices: a list containing the indices of target neurons in data tensor\n",
    "For some animals the data is collected within two sessions that are indicated by session_x\n",
    "\"\"\"\n",
    "\n",
    "with h5py.File(os.path.join(data_path, 'npc_v4_data.h5')) as hf:\n",
    "    print(hf.keys())\n",
    "    images_n = np.array(hf['images']['naturalistic'])\n",
    "    neural_n = np.array(hf['neural']['naturalistic']['monkey_m']['stretch']['session_2'])\n",
    "\n",
    "print(neural_n.shape)\n",
    "n_images = neural_n.shape[1]\n",
    "n_neurons = neural_n.shape[2]\n",
    "size_imags = images_n.shape[0]\n",
    "\n",
    "img = np.zeros((images_n.shape[0], images_n[0].shape[0], images_n[0].shape[1], 3), dtype=np.uint8)\n",
    "for i in range(640):\n",
    "    rgb_img = np.zeros((images_n[i].shape[0], images_n[i].shape[1], 3), dtype=np.uint8)\n",
    "    rgb_img[:, :, 0] = images_n[i]\n",
    "    rgb_img[:, :, 1] = images_n[i]\n",
    "    rgb_img[:, :, 2] = images_n[i]\n",
    "    img[i] = rgb_img\n",
    "\n",
    "\n",
    "print('img: ', img.shape)\n",
    "# for data in images_n:\n",
    "#     plt.imshow(data)\n",
    "print(images_n.shape)\n",
    "print(neural_n.shape)\n",
    "print(n_images, n_neurons, size_imags)\n",
    "\n",
    "reps = neural_n.shape[0]\n",
    "rand_ind = np.arange(reps)\n",
    "np.random.shuffle(rand_ind)\n",
    "\n",
    "\n",
    "data_y_train = neural_n[:,:576].mean(0).astype(np.float32)\n",
    "data_y_val_origin = neural_n[:, 576:].astype(np.float32)\n",
    "data_y_val = data_y_val_origin.mean(0)\n",
    "\n",
    "#data_x = images_n[:, np.newaxis].astype(np.float32)\n",
    "data_x = img\n",
    "print('images_n', images_n.shape)\n",
    "print(data_x.shape)\n",
    "\n",
    "data_x = data_x / 255 # (640, 1, 299, 299)\n",
    "\n",
    "print(type(data_x))\n",
    "\n",
    "print(data_x.shape)\n",
    "#data_x = np.tile(data_x, [1, 3, 1, 1])\n",
    "data_x = np.transpose(data_x, (0, 3, 1, 2))\n",
    "print('data_x', data_x.shape)\n",
    "data_x_train = data_x[:576]\n",
    "data_x_val = data_x[576:]\n",
    "\n",
    "\n",
    "class Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, data_x, data_y):\n",
    "        self.data_x = data_x\n",
    "        self.data_y = data_y\n",
    "    def __getitem__(self, index):\n",
    "        return self.data_x[index], self.data_y[index]\n",
    "    def __len__(self):\n",
    "        return self.data_x.shape[0]\n",
    "\n",
    "imagenet_mean = torch.tensor([0.485, 0.456, 0.406], dtype=torch.float32).view(1, 3, 1, 1).to(device)\n",
    "imagenet_std = torch.tensor([0.229, 0.224, 0.225], dtype=torch.float32).view(1, 3, 1, 1).to(device)\n",
    "transform = lambda x : (x - imagenet_mean) / imagenet_std\n",
    "\n",
    "dataset_train = Dataset(data_x_train, data_y_train)\n",
    "dataset_val = Dataset(data_x_val, data_y_val)\n",
    "\n",
    "loader_train = torch.utils.data.DataLoader(dataset_train, batch_size=batch_size)\n",
    "loader_val = torch.utils.data.DataLoader(dataset_val, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem (a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "()"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: torch.Size([1, 3, 299, 299])\n",
      "fmap:  torch.Size([1, 384, 17, 17])\n",
      "size:  torch.Size([17, 17])\n",
      "52 torch.Size([17, 17])\n",
      "torch.Size([52, 17, 17])\n"
     ]
    }
   ],
   "source": [
    "# CHOOSE THE AUGMENTS IF NECESSARY\n",
    "lamd_s, lamd_d = [1e-1, 1e-1] # the coefficients of the losses. Try other coefficients!\n",
    "epoches = 100 # total epochs for training the encoder\n",
    "lr = 1e-1 # the learing rate for training the encoder\n",
    "\n",
    "alexnet = models.alexnet(pretrained=True)\n",
    "alexnet.to(device)\n",
    "alexnet.eval()\n",
    "for param in alexnet.parameters():\n",
    "    param.requires_grad_(False)\n",
    "\n",
    "x = torch.from_numpy(data_x[0:1]).float().to(device)\n",
    "print(\"x:\", x.shape)\n",
    "fmap = alexnet(x, layer=insp_layer)\n",
    "\n",
    "neurons = data_y_train.shape[1]\n",
    "sizes = fmap.shape[2:]\n",
    "print(\"fmap: \", fmap.shape)\n",
    "print(\"size: \", sizes)\n",
    "channels = fmap.shape[1]\n",
    "print(neurons, sizes)\n",
    "w_s = nn.Parameter(torch.randn(size=(neurons,) + sizes))\n",
    "print(w_s.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class conv_encoder(nn.Module):\n",
    "\n",
    "    def __init__(self, neurons, sizes, channels):\n",
    "        super(conv_encoder, self).__init__()\n",
    "        # PUT YOUR CODES HERE\n",
    "        self.W_s = nn.Parameter(torch.randn(size=(neurons,) + sizes))\n",
    "        self.W_d = nn.Parameter(torch.randn(size = (neurons,channels,1,1)))\n",
    "        self.W_b = nn.Parameter(torch.randn(size = (1,neurons)))\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        # PUT YOUR CODES HERE\n",
    "        out = torch.einsum('bchw , nhw -> bnchw',x,self.W_s) # dimension : N,n,C,h,w\n",
    "        out = torch.stack(\n",
    "            [F.conv2d(out[:,n,:,:,:],torch.unsqueeze(self.W_d[n],0)) for n in range(neurons)],dim=1) \n",
    "            #dimension:N,n,1,h,w\n",
    "        out = torch.sum(out,dim=(2,3,4))\n",
    "        out = out + self.W_b\n",
    "        return out\n",
    "\n",
    "def L_e(y,pred):\n",
    "    return torch.mean(torch.sqrt(torch.sum((y-pred)**2,dim=1)))\n",
    "\n",
    "def L_2(W_s,W_d,lamd_s=lamd_s,lamd_d=lamd_d):\n",
    "    return lamd_s * torch.sum(W_s**2) + lamd_d * torch.sum(W_d**2)\n",
    "\n",
    "K = torch.tensor([\n",
    "    [0,-1,0],\n",
    "    [-1,4,-1],\n",
    "    [0,-1,0]],dtype=torch.float).to(device)\n",
    "def L_laplace(W_s,lamd_s=lamd_s):\n",
    "    return lamd_s * torch.sum(F.conv2d(torch.unsqueeze(W_s,1),K.unsqueeze(0).unsqueeze(0))**2)\n",
    "\n",
    "\n",
    "#encoder = conv_encoder(neurons, sizes, channels).to(device)\n",
    "encoder = conv_encoder(neurons, sizes, channels).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "'\\n    You need to define the conv_encoder() class and train the encoder.\\n    The code of alexnet has been slightly modified from the torchvision, for convenience\\n    of extracting the middle layers.\\n    \\n    Example:\\n        >>> x = x.to(device) # x is a batch of images\\n        >>> x = transform(x)\\n        >>> fmap = alexnet(x, layer=insp_layer)\\n        >>> out= encoder(fmap)\\n        >>> ...\\n'"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def train_model(encoder, optimizer):\n",
    "    losses = []\n",
    "    encoder.train()\n",
    "    for i,(x,y) in enumerate(loader_train):\n",
    "        optimizer.zero_grad()\n",
    "        x = x.float().to(device)\n",
    "        y = y.float().to(device)\n",
    "        x = transform(x)\n",
    "        fmap = alexnet(x,layer = insp_layer)\n",
    "        out = encoder(fmap)\n",
    "        l_e = L_e(y,out)\n",
    "        l_2 = L_2(encoder.W_s,encoder.W_d)\n",
    "        l_l = L_laplace(encoder.W_s)\n",
    "#         print(f'L_e = {l_e} , L_2 = {l_2} , L_l = {l_l}')\n",
    "        loss = L_e(y,out) + L_2(encoder.W_s,encoder.W_d) + L_laplace(encoder.W_s)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        losses.append(loss.item())\n",
    "#         print(f'iteration {i}, train loss: {losses[-1]}')\n",
    "    \n",
    "    return losses\n",
    "\n",
    "def validate_model(encoder):\n",
    "    encoder.eval()\n",
    "    y_pred = []\n",
    "    y_true = []\n",
    "    losses = []\n",
    "    for i,(x,y) in enumerate(loader_val):\n",
    "        x = x.float().to(device)\n",
    "        y = y.float().to(device)\n",
    "        x = transform(x)\n",
    "        fmap = alexnet(x,layer = insp_layer)\n",
    "        out = encoder(fmap)\n",
    "        y_pred.append(out)\n",
    "        y_true.append(y)\n",
    "        l_e = L_e(y,out)\n",
    "        l_2 = L_2(encoder.W_s,encoder.W_d)\n",
    "        l_l = L_laplace(encoder.W_s)\n",
    "        print(f'L_e = {l_e} , L_2 = {l_2} , L_l = {l_l}')\n",
    "        loss = L_e(y,out) + L_2(encoder.W_s,encoder.W_d) + L_laplace(encoder.W_s)\n",
    "        losses.append(loss.item())\n",
    "    y_pred = torch.cat(y_pred)\n",
    "    y_true = torch.cat(y_true)\n",
    "    explained_variance = metrics.explained_variance_score(y_true = y_true.detach().cpu().numpy(),y_pred = y_pred.detach().cpu().numpy())\n",
    "    return explained_variance,sum(losses)/len(losses)\n",
    "\n",
    "\"\"\"\n",
    "    You need to define the conv_encoder() class and train the encoder.\n",
    "    The code of alexnet has been slightly modified from the torchvision, for convenience\n",
    "    of extracting the middle layers.\n",
    "    \n",
    "    Example:\n",
    "        >>> x = x.to(device) # x is a batch of images\n",
    "        >>> x = transform(x)\n",
    "        >>> fmap = alexnet(x, layer=insp_layer)\n",
    "        >>> out= encoder(fmap)\n",
    "        >>> ...\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# losses_train = []\n",
    "# losses_val = []\n",
    "# EVs = []\n",
    "\n",
    "losses_train = []\n",
    "losses_val = []\n",
    "EVs = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "lr = 1e-1\n",
    "optimizer = torch.optim.Adam(encoder.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\anaconda3\\envs\\neural_control\\lib\\site-packages\\ipykernel_launcher.py:1: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/100 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "88dc23bfd41f4461b508c2ff9d88cc15"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L_e = 7420.4013671875 , L_2 = 2482.119873046875 , L_l = 7769.51123046875\n",
      "epoch 0, EV = -1399385.7241586538, val  loss = 17672.033203125 , train loss 26490.6763671875\n",
      "L_e = 3917.556884765625 , L_2 = 1909.12744140625 , L_l = 3358.6171875\n",
      "epoch 1, EV = -506096.8931039664, val  loss = 9185.3017578125 , train loss 13538.28681640625\n",
      "L_e = 2247.81005859375 , L_2 = 1512.765869140625 , L_l = 1665.7581787109375\n",
      "epoch 2, EV = -171477.36987304688, val  loss = 5426.333984375 , train loss 7521.06201171875\n",
      "L_e = 1487.15673828125 , L_2 = 1229.436767578125 , L_l = 863.9611206054688\n",
      "epoch 3, EV = -77634.0573073167, val  loss = 3580.5546875 , train loss 4512.265673828125\n",
      "L_e = 1170.474365234375 , L_2 = 1028.140625 , L_l = 462.734130859375\n",
      "epoch 4, EV = -42386.541370098406, val  loss = 2661.34912109375 , train loss 3123.770703125\n",
      "L_e = 739.4674072265625 , L_2 = 878.2166137695312 , L_l = 259.82757568359375\n",
      "epoch 5, EV = -20668.60581970215, val  loss = 1877.51171875 , train loss 2231.2570556640626\n",
      "L_e = 553.8003540039062 , L_2 = 760.481201171875 , L_l = 149.07127380371094\n",
      "epoch 6, EV = -11412.13635629874, val  loss = 1463.352783203125 , train loss 1634.8057739257813\n",
      "L_e = 399.5477600097656 , L_2 = 664.5747680664062 , L_l = 87.54729461669922\n",
      "epoch 7, EV = -6178.762638183741, val  loss = 1151.6697998046875 , train loss 1245.0056884765625\n",
      "L_e = 1234.9395751953125 , L_2 = 587.9608764648438 , L_l = 52.66838455200195\n",
      "epoch 8, EV = -7023.130448263425, val  loss = 1875.5687255859375 , train loss 1650.2288940429687\n",
      "L_e = 1706.468017578125 , L_2 = 526.011962890625 , L_l = 33.04133987426758\n",
      "epoch 9, EV = -13561.630700244354, val  loss = 2265.521240234375 , train loss 1826.91904296875\n",
      "L_e = 590.7628173828125 , L_2 = 472.05987548828125 , L_l = 21.2829647064209\n",
      "epoch 10, EV = -2329.597590937064, val  loss = 1084.105712890625 , train loss 1412.9687072753907\n",
      "L_e = 296.15960693359375 , L_2 = 424.56658935546875 , L_l = 13.982977867126465\n",
      "epoch 11, EV = -1735.1996405537311, val  loss = 734.7091674804688 , train loss 918.2729614257812\n",
      "L_e = 183.86688232421875 , L_2 = 382.1156005859375 , L_l = 9.303115844726562\n",
      "epoch 12, EV = -1399.134521672359, val  loss = 575.2855834960938 , train loss 635.3749694824219\n",
      "L_e = 128.9326171875 , L_2 = 343.6819763183594 , L_l = 6.344310760498047\n",
      "epoch 13, EV = -633.476437160602, val  loss = 478.9588928222656 , train loss 497.59791870117186\n",
      "L_e = 94.1024169921875 , L_2 = 309.4466857910156 , L_l = 4.521860599517822\n",
      "epoch 14, EV = -360.81615451780647, val  loss = 408.0709533691406 , train loss 425.7371368408203\n",
      "L_e = 77.2410888671875 , L_2 = 279.01800537109375 , L_l = 3.382500410079956\n",
      "epoch 15, EV = -225.45577002144776, val  loss = 359.6416015625 , train loss 360.91993103027346\n",
      "L_e = 317.97198486328125 , L_2 = 252.08627319335938 , L_l = 2.756830930709839\n",
      "epoch 16, EV = -335.5639084348312, val  loss = 572.8150634765625 , train loss 321.71265869140626\n",
      "L_e = 423.29638671875 , L_2 = 229.6016845703125 , L_l = 2.253040075302124\n",
      "epoch 17, EV = -901.3076271002109, val  loss = 655.151123046875 , train loss 925.5555603027344\n",
      "L_e = 291.08306884765625 , L_2 = 210.50015258789062 , L_l = 1.5870990753173828\n",
      "epoch 18, EV = -1405.4287776534375, val  loss = 503.1703186035156 , train loss 789.2316955566406\n",
      "L_e = 2654.716552734375 , L_2 = 193.6607666015625 , L_l = 1.4883702993392944\n",
      "epoch 19, EV = -16221.720730723096, val  loss = 2849.86572265625 , train loss 740.4358428955078\n",
      "L_e = 812.396484375 , L_2 = 177.84591674804688 , L_l = 1.363027572631836\n",
      "epoch 20, EV = -3244.634819155702, val  loss = 991.60546875 , train loss 1466.4305877685547\n",
      "L_e = 310.63873291015625 , L_2 = 163.56983947753906 , L_l = 1.1961618661880493\n",
      "epoch 21, EV = -4659.167856599276, val  loss = 475.40472412109375 , train loss 1170.3984466552733\n",
      "L_e = 149.5836181640625 , L_2 = 150.6344451904297 , L_l = 1.1378635168075562\n",
      "epoch 22, EV = -1274.482249195759, val  loss = 301.35595703125 , train loss 562.4190124511719\n",
      "L_e = 181.16342163085938 , L_2 = 138.93551635742188 , L_l = 1.147420883178711\n",
      "epoch 23, EV = -430.60840119536107, val  loss = 321.2463684082031 , train loss 309.61312408447264\n",
      "L_e = 111.35664367675781 , L_2 = 128.14950561523438 , L_l = 0.8864208459854126\n",
      "epoch 24, EV = -130.6836703121662, val  loss = 240.39256286621094 , train loss 276.72154693603517\n",
      "L_e = 51.44868469238281 , L_2 = 118.4686279296875 , L_l = 0.7678598165512085\n",
      "epoch 25, EV = -80.03737076543845, val  loss = 170.68516540527344 , train loss 241.88961944580078\n",
      "L_e = 104.70333862304688 , L_2 = 109.6677474975586 , L_l = 0.7372499108314514\n",
      "epoch 26, EV = -145.49398619051163, val  loss = 215.10833740234375 , train loss 197.22443389892578\n",
      "L_e = 130.56634521484375 , L_2 = 101.65258026123047 , L_l = 0.7210198640823364\n",
      "epoch 27, EV = -149.41216510992783, val  loss = 232.93995666503906 , train loss 173.33326568603516\n",
      "L_e = 59.553558349609375 , L_2 = 94.35459899902344 , L_l = 0.6591152548789978\n",
      "epoch 28, EV = -59.02373989384908, val  loss = 154.56727600097656 , train loss 162.2132583618164\n",
      "L_e = 8659.11328125 , L_2 = 90.44307708740234 , L_l = 0.8331305384635925\n",
      "epoch 29, EV = -179872.5985796532, val  loss = 8750.3896484375 , train loss 2131.2385543823243\n",
      "L_e = 3120.353759765625 , L_2 = 85.88465118408203 , L_l = 0.8332763910293579\n",
      "epoch 30, EV = -44780.62270876536, val  loss = 3207.07177734375 , train loss 5214.2515869140625\n",
      "L_e = 3822.4765625 , L_2 = 82.94390106201172 , L_l = 0.8056581616401672\n",
      "epoch 31, EV = -88175.62152916078, val  loss = 3906.22607421875 , train loss 3327.5285034179688\n",
      "L_e = 6512.68798828125 , L_2 = 77.1068115234375 , L_l = 0.8700504302978516\n",
      "epoch 32, EV = -168537.00433877684, val  loss = 6590.6650390625 , train loss 3648.86875\n",
      "L_e = 2073.76416015625 , L_2 = 73.53278350830078 , L_l = 0.9717828035354614\n",
      "epoch 33, EV = -69789.4747358572, val  loss = 2148.2685546875 , train loss 3834.955920410156\n",
      "L_e = 10970.28125 , L_2 = 65.53997802734375 , L_l = 0.989351212978363\n",
      "epoch 34, EV = -321430.64521472156, val  loss = 11036.810546875 , train loss 5904.61865234375\n",
      "L_e = 3005.45849609375 , L_2 = 60.5295295715332 , L_l = 1.1332446336746216\n",
      "epoch 35, EV = -12720.802633604178, val  loss = 3067.121337890625 , train loss 5553.712902832031\n",
      "L_e = 5191.94677734375 , L_2 = 59.488704681396484 , L_l = 1.185479760169983\n",
      "epoch 36, EV = -151234.78975679554, val  loss = 5252.62109375 , train loss 2588.875177001953\n",
      "L_e = 382.80438232421875 , L_2 = 54.34695053100586 , L_l = 1.2288657426834106\n",
      "epoch 37, EV = -8552.859537254159, val  loss = 438.38018798828125 , train loss 2133.8293579101564\n",
      "L_e = 393.21923828125 , L_2 = 51.5633659362793 , L_l = 1.169051170349121\n",
      "epoch 38, EV = -7607.695725435247, val  loss = 445.9516296386719 , train loss 1068.278515625\n",
      "L_e = 877.6098022460938 , L_2 = 48.015254974365234 , L_l = 1.0920946598052979\n",
      "epoch 39, EV = -6486.842736396652, val  loss = 926.7171630859375 , train loss 899.8007568359375\n",
      "L_e = 161.8552703857422 , L_2 = 44.98859786987305 , L_l = 1.0080437660217285\n",
      "epoch 40, EV = -889.2241807969717, val  loss = 207.85191345214844 , train loss 453.1959915161133\n",
      "L_e = 82.40904998779297 , L_2 = 42.32902908325195 , L_l = 0.9487406611442566\n",
      "epoch 41, EV = -264.82806634444455, val  loss = 125.68682098388672 , train loss 246.90396575927736\n",
      "L_e = 62.960693359375 , L_2 = 39.71428680419922 , L_l = 0.8701805472373962\n",
      "epoch 42, EV = -103.51622888216606, val  loss = 103.54515838623047 , train loss 106.00133361816407\n",
      "L_e = 2939.4013671875 , L_2 = 39.190303802490234 , L_l = 0.9682396054267883\n",
      "epoch 43, EV = -13277.222514512447, val  loss = 2979.559814453125 , train loss 2066.294618988037\n",
      "L_e = 8350.669921875 , L_2 = 38.26100540161133 , L_l = 1.1412047147750854\n",
      "epoch 44, EV = -140471.4249539295, val  loss = 8390.072265625 , train loss 6502.705834960938\n",
      "L_e = 2645.364501953125 , L_2 = 36.204559326171875 , L_l = 1.3628700971603394\n",
      "epoch 45, EV = -20176.09423004549, val  loss = 2682.931884765625 , train loss 6549.446362304688\n",
      "L_e = 2270.723876953125 , L_2 = 34.913509368896484 , L_l = 1.3235187530517578\n",
      "epoch 46, EV = -30725.634469852997, val  loss = 2306.9609375 , train loss 1932.6202575683594\n",
      "L_e = 1012.7353515625 , L_2 = 33.003936767578125 , L_l = 1.2090860605239868\n",
      "epoch 47, EV = -12255.216103608791, val  loss = 1046.9483642578125 , train loss 1046.695263671875\n",
      "L_e = 224.62210083007812 , L_2 = 30.71657943725586 , L_l = 1.074163794517517\n",
      "epoch 48, EV = -1720.1028571724892, val  loss = 256.412841796875 , train loss 484.0513656616211\n",
      "L_e = 78.67961120605469 , L_2 = 28.7170467376709 , L_l = 0.962542712688446\n",
      "epoch 49, EV = -121.98000921308994, val  loss = 108.35919952392578 , train loss 173.58938903808593\n",
      "L_e = 43.39177703857422 , L_2 = 26.949411392211914 , L_l = 0.8608434796333313\n",
      "epoch 50, EV = -78.40075362989536, val  loss = 71.2020263671875 , train loss 96.42626190185547\n",
      "L_e = 1213.0599365234375 , L_2 = 27.011043548583984 , L_l = 1.0438859462738037\n",
      "epoch 51, EV = -1207.7739054778447, val  loss = 1241.1148681640625 , train loss 2528.9007469177245\n",
      "L_e = 1072.429931640625 , L_2 = 25.774385452270508 , L_l = 1.0691715478897095\n",
      "epoch 52, EV = -16334.503570933755, val  loss = 1099.2735595703125 , train loss 1951.4841674804688\n",
      "L_e = 533.597412109375 , L_2 = 24.060441970825195 , L_l = 1.0091077089309692\n",
      "epoch 53, EV = -2289.373512647473, val  loss = 558.6669311523438 , train loss 1936.6286193847657\n",
      "L_e = 1468.22265625 , L_2 = 23.37224769592285 , L_l = 0.9318470358848572\n",
      "epoch 54, EV = -21770.42583482655, val  loss = 1492.5267333984375 , train loss 1308.5370819091797\n",
      "L_e = 449.6911926269531 , L_2 = 21.758638381958008 , L_l = 0.8958029747009277\n",
      "epoch 55, EV = -4833.953295455529, val  loss = 472.34564208984375 , train loss 848.9953063964844\n",
      "L_e = 133.55905151367188 , L_2 = 20.549331665039062 , L_l = 0.8445873260498047\n",
      "epoch 56, EV = -287.71769556288535, val  loss = 154.95297241210938 , train loss 276.1713264465332\n",
      "L_e = 52.18512725830078 , L_2 = 19.49367332458496 , L_l = 0.7981659770011902\n",
      "epoch 57, EV = -94.9100351035595, val  loss = 72.47696685791016 , train loss 154.0948516845703\n",
      "L_e = 13716.357421875 , L_2 = 21.30422592163086 , L_l = 0.7598150372505188\n",
      "epoch 58, EV = -457665.7289290382, val  loss = 13738.421875 , train loss 5107.802584838867\n",
      "L_e = 3388.34814453125 , L_2 = 20.122323989868164 , L_l = 0.9775239825248718\n",
      "epoch 59, EV = -39258.96449289299, val  loss = 3409.447998046875 , train loss 6528.985140991211\n",
      "L_e = 342.3717346191406 , L_2 = 20.044864654541016 , L_l = 1.2712959051132202\n",
      "epoch 60, EV = -9803.59324404368, val  loss = 363.6878967285156 , train loss 2402.5167449951173\n",
      "L_e = 289.5584716796875 , L_2 = 18.098981857299805 , L_l = 1.1738063097000122\n",
      "epoch 61, EV = -4146.919372984996, val  loss = 308.83123779296875 , train loss 1117.9979431152344\n",
      "L_e = 357.5086669921875 , L_2 = 17.111492156982422 , L_l = 1.1447372436523438\n",
      "epoch 62, EV = -898.8874472219211, val  loss = 375.764892578125 , train loss 566.2603439331054\n",
      "L_e = 167.70326232910156 , L_2 = 16.206003189086914 , L_l = 1.032023549079895\n",
      "epoch 63, EV = -2082.433739314859, val  loss = 184.94129943847656 , train loss 300.7564666748047\n",
      "L_e = 79.65188598632812 , L_2 = 15.641582489013672 , L_l = 0.9874001741409302\n",
      "epoch 64, EV = -413.2101842107681, val  loss = 96.28087615966797 , train loss 140.7084732055664\n",
      "L_e = 82.1722412109375 , L_2 = 14.580000877380371 , L_l = 0.8960887789726257\n",
      "epoch 65, EV = -198.35063842512093, val  loss = 97.64833068847656 , train loss 97.56586074829102\n",
      "L_e = 2600.579833984375 , L_2 = 14.416570663452148 , L_l = 0.8408843278884888\n",
      "epoch 66, EV = -12505.88989678713, val  loss = 2615.837158203125 , train loss 1657.4770286560058\n",
      "L_e = 5085.17822265625 , L_2 = 15.136541366577148 , L_l = 0.9582986831665039\n",
      "epoch 67, EV = -59490.87420474451, val  loss = 5101.2734375 , train loss 2448.1528045654295\n",
      "L_e = 481.0542907714844 , L_2 = 15.072741508483887 , L_l = 1.0272692441940308\n",
      "epoch 68, EV = -10647.551488854564, val  loss = 497.1543273925781 , train loss 2026.1112930297852\n",
      "L_e = 404.4137268066406 , L_2 = 14.04603099822998 , L_l = 1.0707505941390991\n",
      "epoch 69, EV = -7512.148122394314, val  loss = 419.5304870605469 , train loss 1064.8528747558594\n",
      "L_e = 258.6556396484375 , L_2 = 12.83144760131836 , L_l = 1.1532992124557495\n",
      "epoch 70, EV = -613.9398627888697, val  loss = 272.640380859375 , train loss 617.2438171386718\n",
      "L_e = 181.0641326904297 , L_2 = 12.131462097167969 , L_l = 1.2298288345336914\n",
      "epoch 71, EV = -1046.028329292169, val  loss = 194.4254150390625 , train loss 387.2846031188965\n",
      "L_e = 91.43915557861328 , L_2 = 11.447196006774902 , L_l = 1.124133825302124\n",
      "epoch 72, EV = -101.38563818427232, val  loss = 104.01048278808594 , train loss 192.62909240722655\n",
      "L_e = 208.22555541992188 , L_2 = 11.253705024719238 , L_l = 1.0122555494308472\n",
      "epoch 73, EV = -178.50263093411922, val  loss = 220.49151611328125 , train loss 5251.146062469483\n",
      "L_e = 3264.073486328125 , L_2 = 14.18478012084961 , L_l = 1.0667842626571655\n",
      "epoch 74, EV = -83467.8342082512, val  loss = 3279.3251953125 , train loss 5800.315716552735\n",
      "L_e = 4790.060546875 , L_2 = 13.858444213867188 , L_l = 1.1430953741073608\n",
      "epoch 75, EV = -109214.39938356212, val  loss = 4805.06201171875 , train loss 3229.0738220214844\n",
      "L_e = 316.9109802246094 , L_2 = 12.125663757324219 , L_l = 1.252976894378662\n",
      "epoch 76, EV = -6472.773124918342, val  loss = 330.2896423339844 , train loss 1979.753598022461\n",
      "L_e = 269.0959777832031 , L_2 = 11.478748321533203 , L_l = 1.5193389654159546\n",
      "epoch 77, EV = -3647.1534972087693, val  loss = 282.0940856933594 , train loss 584.2308715820312\n",
      "L_e = 161.1832275390625 , L_2 = 10.680916786193848 , L_l = 1.5099716186523438\n",
      "epoch 78, EV = -1320.2060481057717, val  loss = 173.37411499023438 , train loss 583.0125793457031\n",
      "L_e = 596.7175903320312 , L_2 = 9.642699241638184 , L_l = 1.4199984073638916\n",
      "epoch 79, EV = -959.4613401970038, val  loss = 607.7802734375 , train loss 334.0343994140625\n",
      "L_e = 128.28518676757812 , L_2 = 8.965348243713379 , L_l = 1.2523813247680664\n",
      "epoch 80, EV = -438.03819081072623, val  loss = 138.50291442871094 , train loss 353.49635925292966\n",
      "L_e = 147.96405029296875 , L_2 = 8.508928298950195 , L_l = 1.115776538848877\n",
      "epoch 81, EV = -172.11383844568178, val  loss = 157.58876037597656 , train loss 169.47029571533204\n",
      "L_e = 41125.48828125 , L_2 = 15.361371994018555 , L_l = 1.1037315130233765\n",
      "epoch 82, EV = -3741989.948218121, val  loss = 41141.95703125 , train loss 559.8467979431152\n",
      "L_e = 1407.1326904296875 , L_2 = 12.605264663696289 , L_l = 1.1843122243881226\n",
      "epoch 83, EV = -66736.58672047693, val  loss = 1420.9222412109375 , train loss 9409.441711425781\n",
      "L_e = 223.3043670654297 , L_2 = 9.368785858154297 , L_l = 1.353176236152649\n",
      "epoch 84, EV = -1321.8696902680856, val  loss = 234.02633666992188 , train loss 1888.7619232177735\n",
      "L_e = 1447.286865234375 , L_2 = 9.680782318115234 , L_l = 1.3560898303985596\n",
      "epoch 85, EV = -7002.214474781202, val  loss = 1458.32373046875 , train loss 442.4668899536133\n",
      "L_e = 1825.132568359375 , L_2 = 8.493624687194824 , L_l = 1.2282005548477173\n",
      "epoch 86, EV = -18235.97307425852, val  loss = 1834.8543701171875 , train loss 1313.3216522216796\n",
      "L_e = 771.8037719726562 , L_2 = 8.235206604003906 , L_l = 1.2128422260284424\n",
      "epoch 87, EV = -1831.061386714761, val  loss = 781.2518310546875 , train loss 962.5671279907226\n",
      "L_e = 354.53912353515625 , L_2 = 7.773133277893066 , L_l = 1.0646144151687622\n",
      "epoch 88, EV = -1865.394403935625, val  loss = 363.3768615722656 , train loss 410.2574096679688\n",
      "L_e = 160.12191772460938 , L_2 = 7.716407775878906 , L_l = 1.102646827697754\n",
      "epoch 89, EV = -1486.7657422652612, val  loss = 168.9409637451172 , train loss 353.59846649169924\n",
      "L_e = 208.3801727294922 , L_2 = 7.107532501220703 , L_l = 0.9804345369338989\n",
      "epoch 90, EV = -470.2457768871234, val  loss = 216.4681396484375 , train loss 273.3061683654785\n",
      "L_e = 4015.40673828125 , L_2 = 7.2519049644470215 , L_l = 0.8794136047363281\n",
      "epoch 91, EV = -27696.256613518184, val  loss = 4023.5380859375 , train loss 131.4171585083008\n",
      "L_e = 525.0701904296875 , L_2 = 7.510603904724121 , L_l = 0.9881613850593567\n",
      "epoch 92, EV = -4351.712971510796, val  loss = 533.5689697265625 , train loss 4559.909530639648\n",
      "L_e = 1878.155517578125 , L_2 = 9.645605087280273 , L_l = 1.2401951551437378\n",
      "epoch 93, EV = -86933.57615564534, val  loss = 1889.0413818359375 , train loss 1976.5152587890625\n",
      "L_e = 934.02880859375 , L_2 = 10.927245140075684 , L_l = 1.3615922927856445\n",
      "epoch 94, EV = -40382.6101959428, val  loss = 946.317626953125 , train loss 1185.553515625\n",
      "L_e = 646.1715087890625 , L_2 = 8.588187217712402 , L_l = 1.3797639608383179\n",
      "epoch 95, EV = -4747.545372161728, val  loss = 656.1394653320312 , train loss 1388.4063598632813\n",
      "L_e = 1002.3760375976562 , L_2 = 8.286371231079102 , L_l = 1.4884072542190552\n",
      "epoch 96, EV = -30546.343833146188, val  loss = 1012.1508178710938 , train loss 1138.0256958007812\n",
      "L_e = 146.7181854248047 , L_2 = 7.207055568695068 , L_l = 1.4324768781661987\n",
      "epoch 97, EV = -369.3318806015528, val  loss = 155.35772705078125 , train loss 470.0524627685547\n",
      "L_e = 71.27156829833984 , L_2 = 6.657655239105225 , L_l = 1.2818197011947632\n",
      "epoch 98, EV = -190.24399500741407, val  loss = 79.21104431152344 , train loss 161.40181045532228\n",
      "L_e = 61.014251708984375 , L_2 = 6.037018299102783 , L_l = 1.0613243579864502\n",
      "epoch 99, EV = -161.75799055512135, val  loss = 68.11259460449219 , train loss 96.25481605529785\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for epoch in tqdm_notebook(range(epoches)):\n",
    "    losses_train += train_model(encoder,optimizer)\n",
    "    ev,loss = validate_model(encoder)\n",
    "    EVs.append(ev)\n",
    "    losses_val.append(loss)\n",
    "    print(f'epoch {epoch}, EV = {ev}, val  loss = {loss} , train loss {sum(losses_train[-10:])/10}')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../models/exp9.pt'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp\\3\\ipykernel_26896\\341107563.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[0mexp\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;36m9\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 2\u001B[1;33m \u001B[0mtorch\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msave\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mencoder\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;34mf'../models/exp{exp}.pt'\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[1;32m~\\anaconda3\\envs\\neural_control\\lib\\site-packages\\torch\\serialization.py\u001B[0m in \u001B[0;36msave\u001B[1;34m(obj, f, pickle_module, pickle_protocol, _use_new_zipfile_serialization)\u001B[0m\n\u001B[0;32m    367\u001B[0m     \u001B[0m_check_dill_version\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mpickle_module\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    368\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 369\u001B[1;33m     \u001B[1;32mwith\u001B[0m \u001B[0m_open_file_like\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mf\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;34m'wb'\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0mopened_file\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    370\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0m_use_new_zipfile_serialization\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    371\u001B[0m             \u001B[1;32mwith\u001B[0m \u001B[0m_open_zipfile_writer\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mopened_file\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0mopened_zipfile\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\envs\\neural_control\\lib\\site-packages\\torch\\serialization.py\u001B[0m in \u001B[0;36m_open_file_like\u001B[1;34m(name_or_buffer, mode)\u001B[0m\n\u001B[0;32m    228\u001B[0m \u001B[1;32mdef\u001B[0m \u001B[0m_open_file_like\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mname_or_buffer\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mmode\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    229\u001B[0m     \u001B[1;32mif\u001B[0m \u001B[0m_is_path\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mname_or_buffer\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 230\u001B[1;33m         \u001B[1;32mreturn\u001B[0m \u001B[0m_open_file\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mname_or_buffer\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mmode\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    231\u001B[0m     \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    232\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[1;34m'w'\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mmode\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\envs\\neural_control\\lib\\site-packages\\torch\\serialization.py\u001B[0m in \u001B[0;36m__init__\u001B[1;34m(self, name, mode)\u001B[0m\n\u001B[0;32m    209\u001B[0m \u001B[1;32mclass\u001B[0m \u001B[0m_open_file\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0m_opener\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    210\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0m__init__\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mname\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mmode\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 211\u001B[1;33m         \u001B[0msuper\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0m_open_file\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m__init__\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mopen\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mname\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mmode\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    212\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    213\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0m__exit__\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mFileNotFoundError\u001B[0m: [Errno 2] No such file or directory: '../models/exp9.pt'"
     ]
    }
   ],
   "source": [
    "exp = 9\n",
    "torch.save(encoder, f'../models/exp{exp}.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp = '9cpu'\n",
    "\n",
    "encoder = torch.load(f'../models/exp{exp}.pt').to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "-59.02373989384908"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(EVs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "[<matplotlib.lines.Line2D at 0x264c6008908>]"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(losses_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(losses_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(EVs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(EVs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "I = best_x.cpu().detach().numpy()\n",
    "for i in range(5):\n",
    "    fig,axes = plt.subplots(nrows = 1 , ncols = 5,  figsize=(20,4))\n",
    "    for j in range (5):\n",
    "        axes[j].imshow(I[5*i+j][0],interpolation='gaussian',cmap='gray')\n",
    "        axes[j].tick_params(labelbottom=False,labelleft=False,left=False,bottom=False)\n",
    "    fig.suptitle(f\"5 generated images for one hot maximization of neural site {n_id[i]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "show the results"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Problem (b)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# b - Neural site response stretch"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# CHOOSE THE AUGMENTS IF NECESSARY\n",
    "n_id = np.random.randint(0, n_neurons, [5])  #inspect several neurons\n",
    "rep_num = 5  # reptitions of each neuron\n",
    "iters = 200 # iterations for synthesis\n",
    "lr = 5e-3 # learing rate for synthesis\n",
    "jitter = True # jitter the input for imitating the movement of the eyes\n",
    "\n",
    "n_id_torch = torch.tensor(n_id.tolist(), dtype=torch.int64).to(device).repeat_interleave(rep_num).view(-1, 1)\n",
    "\n",
    "def loss_TV(x):\n",
    "    wd = x[:, :, 1:, :] - x[:, :, :-1, :]\n",
    "    hd = x[:, :, :, 1:] - x[:, :, :, :-1]\n",
    "    loss = (wd ** 2).mean([2]).sum() + (hd ** 2).mean([3]).sum()\n",
    "    return loss\n",
    "\n",
    "def jitter_image(img, max_pixels=19):\n",
    "    sx, sy = np.random.randint(-max_pixels, max_pixels, size=2).tolist()\n",
    "    img_shift = img.roll(sx, 3).roll(sy, 2)\n",
    "    return img_shift\n",
    "\n",
    "encoder.eval()\n",
    "for param in encoder.parameters():\n",
    "#     param.requires_grad_(False)\n",
    "    param = param.detach()\n",
    "\n",
    "init_images = np.random.uniform(0, 1, [len(n_id_torch), 1, 299, 299]).astype(np.float32)\n",
    "x = torch.from_numpy(init_images)\n",
    "x = x.to(device)\n",
    "\n",
    "\n",
    "# PUT YOUR CODES HERE\n",
    "\"\"\"\n",
    "    In each iteration, you can use jitter_image() function to jitter the input\n",
    "    image, and use transform predefined to apply standard imagnet preprocess\n",
    "\n",
    "    Example:\n",
    "        >>> x_jittered = jitter_image(x)\n",
    "        >>> x_jittered = transform(x_jitter.repeat([1, 3, 1, 1]))\n",
    "        ...\n",
    "\n",
    "    In addition, it is better to normalize when updating the input image x\n",
    "\n",
    "    Example:\n",
    "        >>> grad = x.grad.detach()\n",
    "        >>> grad /= grad.std([1, 2, 3], keepdim=True) + 1e-8\n",
    "        >>> x = (x - lr * grad).clamp(0, 1).detach()\n",
    "\"\"\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "init_images = np.random.uniform(0, 1, [len(n_id_torch), 1, 299, 299]).astype(np.float32)\n",
    "x = torch.from_numpy(init_images)\n",
    "x = x.to(device)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "losses_tv = []\n",
    "losses_res = []\n",
    "losses = []\n",
    "best_l_res = 0\n",
    "best_x = None"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "lr = 1e-1\n",
    "lamb_tv = 1e-1\n",
    "for i in tqdm_notebook(range(iters)):\n",
    "    x = Variable(x,requires_grad = True)\n",
    "\n",
    "    x_jittered = jitter_image(x,1)\n",
    "\n",
    "    x_jittered = transform(x_jittered.repeat([1, 3, 1, 1]))\n",
    "\n",
    "    fmap = alexnet(x_jittered,layer = insp_layer)\n",
    "\n",
    "    out = encoder(fmap)\n",
    "    l_res = -torch.sum(out.gather(dim=1,index=n_id_torch))\n",
    "    l_tv = loss_TV(x)\n",
    "    loss = l_res + lamb_tv * l_tv\n",
    "\n",
    "    losses_tv.append(l_tv.item())\n",
    "    losses_res.append(l_res.item())\n",
    "    losses.append(loss.item())\n",
    "\n",
    "    print(f'iteration {i}, L_tv = {losses_tv[-1]} , L_res = {losses_res[-1]} , total_loss = {losses[-1]}')\n",
    "    if l_res < best_l_res:\n",
    "        best_x = torch.tensor(x)\n",
    "        best_l_res = l_res\n",
    "\n",
    "    loss.backward()\n",
    "    grad = x.grad.detach()\n",
    "\n",
    "    grad /= grad.std([1, 2, 3], keepdim=True) + 1e-8\n",
    "    x = (x - lr * grad).clamp(0, 1).detach()\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.plot(losses_tv)\n",
    "plt.title(\"TV Loss\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.plot(-np.array(losses_res))\n",
    "plt.title(\"Target neural site response\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.plot(losses)\n",
    "plt.title(\"total loss\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Result images"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# c - One Hot Neural Site Response Maximization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses_tv_oh = []\n",
    "losses_res_oh = []\n",
    "losses_oh = []\n",
    "best_l_oh = 0\n",
    "best_x_oh = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_images = np.random.uniform(0, 1, [len(n_id_torch), 1, 299, 299]).astype(np.float32)\n",
    "x = torch.from_numpy(init_images)\n",
    "x = x.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "lr = 1e-1\n",
    "lamb_tv = 1e-3\n",
    "    \n",
    "# PUT YOUR CODES HERE\n",
    "\"\"\" \n",
    "    In each iteration, you can use jitter_image() function to jitter the input \n",
    "    image, and use transform predefined to apply standard imagnet preprocess\n",
    "    \n",
    "    Example:\n",
    "        >>> x_jittered = jitter_image(x)\n",
    "        >>> x_jittered = transform(x_jitter.repeat([1, 3, 1, 1]))\n",
    "        ...\n",
    "    \n",
    "    In addition, it is better to normalize when updating the input image x\n",
    "    \n",
    "    Example:\n",
    "        >>> grad = x.grad.detach()\n",
    "        >>> grad /= grad.std([1, 2, 3], keepdim=True) + 1e-8\n",
    "        >>> x = (x - lr * grad).clamp(0, 1).detach()    \n",
    "\"\"\"\n",
    "for i in tqdm_notebook(range(iters)):\n",
    "    x = Variable(x,requires_grad = True)\n",
    "\n",
    "    x_jittered = jitter_image(x,max_pixels=5)\n",
    "    x_jittered = transform(x_jittered.repeat([1, 3, 1, 1]))\n",
    "    fmap = alexnet(x_jittered,layer = insp_layer)\n",
    "    out = encoder(fmap)\n",
    "    out = F.softmax(out)\n",
    "    out = out.gather(dim=1,index=n_id_torch)\n",
    "    l_res = -torch.sum(out)\n",
    "    l_tv = loss_TV(x)\n",
    "    loss = l_res + lamb_tv * l_tv\n",
    "    \n",
    "    losses_tv_oh.append(l_tv.item())\n",
    "    losses_res_oh.append(l_res.item())\n",
    "    losses_oh.append(loss.item())\n",
    "    print(f'iteration {i}, L_tv = {losses_tv_oh[-1]} , L_res = {losses_res_oh[-1]} , total_loss = {losses_oh[-1]}')\n",
    "\n",
    "    loss.backward()\n",
    "    \n",
    "    if l_res < best_l_oh:\n",
    "        best_x_oh = torch.tensor(x)\n",
    "        best_l_oh = l_res\n",
    "    grad = x.grad.detach()\n",
    "    grad /= grad.std([1, 2, 3], keepdim=True) + 1e-8\n",
    "    x = (x - lr * grad).clamp(0, 1).detach()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(losses_tv_oh)\n",
    "plt.title(\"TV Loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(-np.array(losses_res_oh))\n",
    "plt.title(\"One hot response\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(losses_oh)\n",
    "plt.title('total loss')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Result images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x = x.cpu().detach().numpy()\n",
    "I_oh = best_x_oh.cpu().detach().numpy()\n",
    "for i in range(5):\n",
    "    fig,axes = plt.subplots(nrows = 1 , ncols = 5,  figsize=(20,4))\n",
    "    for j in range (5):\n",
    "        axes[j].imshow(I_oh[5*i+j][0],interpolation='gaussian',cmap='gray')\n",
    "        axes[j].tick_params(labelbottom=False,labelleft=False,left=False,bottom=False)\n",
    "    fig.suptitle(f\"5 generated images for one hot maximization of neural site {n_id[i]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neural sites have diffrent spatial receptive fields due to the spatial masks W_s. One hot response maximization of a target neural site should lead for the apparition of a localized pattern in the image space."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However most masks were localized at the same spots, on the edges of the feature map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(encoder.W_s.detach().cpu().numpy()[17],cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(encoder.W_s.detach().cpu().numpy()[26],cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(encoder.W_s.detach().cpu().numpy()[13],cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(encoder.W_s.detach().cpu().numpy()[46],cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(encoder.W_s.detach().cpu().numpy()[0],cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "12px",
    "width": "252px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
